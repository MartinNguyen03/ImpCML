{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchbnn as bnn  # torchbnn library for BNN layers\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BayesianNN(nn.Module):\n",
    "    def __init__(self, input_dim, prior_mu, prior_sigma, layer1_units, layer2_units):\n",
    "        super(BayesianNN, self).__init__()\n",
    "        # Define prior parameters\n",
    "        prior_mu = 0.0  # Mean of the prior distribution\n",
    "        prior_sigma = 0.1  # Standard deviation of the prior distribution\n",
    "        \n",
    "        # Initialize Bayesian layers with the specified priors\n",
    "        self.fc1 = bnn.BayesLinear(prior_mu, prior_sigma, in_features=input_dim, out_features=layer1_units)\n",
    "        self.fc2 = bnn.BayesLinear(prior_mu, prior_sigma, in_features=layer1_units, out_features=layer2_units)\n",
    "        self.fc3 = bnn.BayesLinear(prior_mu, prior_sigma, in_features=layer2_units, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayesian_nn(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        # Ensure y_batch has the same shape as y_pred\n",
    "        y_batch = y_batch.unsqueeze(1)  # Convert y_batch shape to (batch_size, 1) if needed\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)  # Now both are of shape (batch_size, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_bayesian_nn(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            all_preds.extend(y_pred.round().squeeze().cpu().numpy())\n",
    "    return np.array(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run BNN for each value of n\n",
    "def run_bayesian_nn(n, hyper_params):\n",
    "    # Load data\n",
    "    X = np.load(f'Datasets/kryptonite-{n}-X.npy')\n",
    "    y = np.load(f'Datasets/kryptonite-{n}-y.npy')\n",
    "    \n",
    "    # Split data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Convert data to PyTorch tensors and create DataLoaders\n",
    "    X_train, y_train = torch.tensor(X_train, dtype=torch.float32).clone().detach(), torch.tensor(y_train, dtype=torch.float32).clone().detach()\n",
    "    X_val, y_val = torch.tensor(X_val, dtype=torch.float32).clone().detach(), torch.tensor(y_val, dtype=torch.float32).clone().detach()\n",
    "    X_test, y_test = torch.tensor(X_test, dtype=torch.float32).clone().detach(), torch.tensor(y_test, dtype=torch.float32).clone().detach()\n",
    "    \n",
    "    # Convert data to PyTorch tensors and create DataLoaders\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=hyper_params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=hyper_params['batch_size'])\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = BayesianNN(input_dim=input_dim, prior_mu=hyper_params['prior_mu'], prior_sigma=hyper_params['prior_sigma'], layer1_units=hyper_params['layer1_units'], layer2_units=hyper_params['layer2_units'])\n",
    "\n",
    "    \n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyper_params['learning_rate'])\n",
    "    \n",
    "    # Train the model and track training loss\n",
    "    training_losses = []\n",
    "    for epoch in range(hyper_params['epochs']):\n",
    "        train_loss = train_bayesian_nn(model, train_loader, criterion, optimizer)\n",
    "        training_losses.append(train_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate the model\n",
    "    y_val_pred = evaluate_bayesian_nn(model, val_loader)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy for n={n}: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    y_test_pred = evaluate_bayesian_nn(model, test_loader)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test Accuracy for n={n}: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 45.2703\n",
      "Function value obtained: -0.4954\n",
      "Current minimum: -0.4954\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 3.1798\n",
      "Function value obtained: -0.4987\n",
      "Current minimum: -0.4987\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 25.9858\n",
      "Function value obtained: -0.5896\n",
      "Current minimum: -0.5896\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 46.7780\n",
      "Function value obtained: -0.9357\n",
      "Current minimum: -0.9357\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 22.9944\n",
      "Function value obtained: -0.5517\n",
      "Current minimum: -0.9357\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 186.2069\n",
      "Function value obtained: -0.5009\n",
      "Current minimum: -0.9357\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 34.8078\n",
      "Function value obtained: -0.9448\n",
      "Current minimum: -0.9448\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 13.3042\n",
      "Function value obtained: -0.9467\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 33.6050\n",
      "Function value obtained: -0.5124\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 29.6442\n",
      "Function value obtained: -0.4991\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 28.2203\n",
      "Function value obtained: -0.9333\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0110\n",
      "Function value obtained: -0.4946\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1894\n",
      "Function value obtained: -0.4889\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 149.6608\n",
      "Function value obtained: -0.5033\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 31.4747\n",
      "Function value obtained: -0.9367\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.7813\n",
      "Function value obtained: -0.5035\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.3250\n",
      "Function value obtained: -0.9428\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.7043\n",
      "Function value obtained: -0.9391\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 30.2469\n",
      "Function value obtained: -0.9393\n",
      "Current minimum: -0.9467\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.2950\n",
      "Function value obtained: -0.9474\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.8106\n",
      "Function value obtained: -0.9387\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.3265\n",
      "Function value obtained: -0.5048\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.3100\n",
      "Function value obtained: -0.9461\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 48.2447\n",
      "Function value obtained: -0.9444\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.3027\n",
      "Function value obtained: -0.4963\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 49.1896\n",
      "Function value obtained: -0.9237\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 28.1799\n",
      "Function value obtained: -0.9448\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.6809\n",
      "Function value obtained: -0.9369\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 28.2021\n",
      "Function value obtained: -0.5009\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 136.7941\n",
      "Function value obtained: -0.9369\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.1607\n",
      "Function value obtained: -0.9396\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 107.2140\n",
      "Function value obtained: -0.8533\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.4381\n",
      "Function value obtained: -0.8909\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.4330\n",
      "Function value obtained: -0.9352\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.9804\n",
      "Function value obtained: -0.9409\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 34.7749\n",
      "Function value obtained: -0.9356\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 35.0728\n",
      "Function value obtained: -0.9361\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.5791\n",
      "Function value obtained: -0.9257\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.8665\n",
      "Function value obtained: -0.9393\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.1200\n",
      "Function value obtained: -0.9309\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 40.1554\n",
      "Function value obtained: -0.9081\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.1893\n",
      "Function value obtained: -0.4972\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.5796\n",
      "Function value obtained: -0.8578\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.2279\n",
      "Function value obtained: -0.9443\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 25.0765\n",
      "Function value obtained: -0.9450\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.9683\n",
      "Function value obtained: -0.9419\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 24.0303\n",
      "Function value obtained: -0.9424\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.9828\n",
      "Function value obtained: -0.9415\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.9795\n",
      "Function value obtained: -0.9311\n",
      "Current minimum: -0.9474\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.5962\n",
      "Function value obtained: -0.9456\n",
      "Current minimum: -0.9474\n",
      "Best hyperparameters found:\n",
      "learning_rate: 0.003992368422485689\n",
      "batch_size: 121\n",
      "layer1_units: 73\n",
      "layer2_units: 54\n",
      "prior_mu: 0.5103986684212475\n",
      "prior_sigma: 0.29950393862614066\n",
      "epochs: 81\n"
     ]
    }
   ],
   "source": [
    "# Define the search space for hyperparameters\n",
    "space = [\n",
    "    Real(1e-5, 1e-1, name='learning_rate'),  # Learning rate\n",
    "    Integer(16, 128, name='batch_size'),     # Batch size\n",
    "    Integer(32, 128, name='layer1_units'),   # Number of units in layer 1\n",
    "    Integer(16, 64, name='layer2_units'),    # Number of units in layer 2\n",
    "    Real(0.0, 1.0, name='prior_mu'),         # Prior mean\n",
    "    Real(0.01, 0.5, name='prior_sigma'),     # Prior sigma\n",
    "    Integer(5, 200, name='epochs')         # Number of epochs\n",
    "]\n",
    "\n",
    "\n",
    "# Objective function to optimize using Gaussian Process\n",
    "@use_named_args(space)\n",
    "def objective_function(learning_rate, batch_size, layer1_units, layer2_units, prior_mu, prior_sigma, epochs, n=9):\n",
    "    # Load the data for the specific dataset\n",
    "    X = np.load(f'Datasets/kryptonite-{n}-X.npy')\n",
    "    y = np.load(f'Datasets/kryptonite-{n}-y.npy')\n",
    "    \n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "    X_val, _, y_val, _ = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Convert to torch tensors and create DataLoader instances\n",
    "    X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    batch_size = int(max(16, batch_size))\n",
    "    # DataLoader for training and validation\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "    # Initialize the model with the given hyperparameters\n",
    "    model = BayesianNN(input_dim=X_train.shape[1], \n",
    "                       prior_mu=prior_mu, prior_sigma=prior_sigma, \n",
    "                       layer1_units=layer1_units, layer2_units=layer2_units)\n",
    "    \n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training the model for a fixed number of epochs\n",
    "    for epoch in range(epochs):  # Use 10 epochs for each optimization trial\n",
    "        train_bayesian_nn(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred = evaluate_bayesian_nn(model, val_loader)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Return the negative validation accuracy to minimize (since gp_minimize tries to minimize the objective)\n",
    "    return -val_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Run Bayesian Optimization with Gaussian Process\n",
    "results = gp_minimize(objective_function, space, n_calls=50, random_state=42, verbose=True)\n",
    "\n",
    "# Print the best found hyperparameters\n",
    "print(\"Best hyperparameters found:\")\n",
    "for param, value in zip(space, results.x):\n",
    "    print(f\"{param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6992\n",
      "Epoch 2, Train Loss: 0.6960\n",
      "Epoch 3, Train Loss: 0.6971\n",
      "Epoch 4, Train Loss: 0.6947\n",
      "Epoch 5, Train Loss: 0.6936\n",
      "Epoch 6, Train Loss: 0.6944\n",
      "Epoch 7, Train Loss: 0.6947\n",
      "Epoch 8, Train Loss: 0.6938\n",
      "Epoch 9, Train Loss: 0.6932\n",
      "Epoch 10, Train Loss: 0.6932\n",
      "Epoch 11, Train Loss: 0.6946\n",
      "Epoch 12, Train Loss: 0.6936\n",
      "Epoch 13, Train Loss: 0.6927\n",
      "Epoch 14, Train Loss: 0.6929\n",
      "Epoch 15, Train Loss: 0.6926\n",
      "Epoch 16, Train Loss: 0.6914\n",
      "Epoch 17, Train Loss: 0.6894\n",
      "Epoch 18, Train Loss: 0.6850\n",
      "Epoch 19, Train Loss: 0.6654\n",
      "Epoch 20, Train Loss: 0.6191\n",
      "Epoch 21, Train Loss: 0.5258\n",
      "Epoch 22, Train Loss: 0.4059\n",
      "Epoch 23, Train Loss: 0.3231\n",
      "Epoch 24, Train Loss: 0.2780\n",
      "Epoch 25, Train Loss: 0.2564\n",
      "Epoch 26, Train Loss: 0.2355\n",
      "Epoch 27, Train Loss: 0.2304\n",
      "Epoch 28, Train Loss: 0.2123\n",
      "Epoch 29, Train Loss: 0.2085\n",
      "Epoch 30, Train Loss: 0.2105\n",
      "Epoch 31, Train Loss: 0.2127\n",
      "Epoch 32, Train Loss: 0.2051\n",
      "Epoch 33, Train Loss: 0.2022\n",
      "Epoch 34, Train Loss: 0.1976\n",
      "Epoch 35, Train Loss: 0.1964\n",
      "Epoch 36, Train Loss: 0.1909\n",
      "Epoch 37, Train Loss: 0.1940\n",
      "Epoch 38, Train Loss: 0.1910\n",
      "Epoch 39, Train Loss: 0.1859\n",
      "Epoch 40, Train Loss: 0.1887\n",
      "Epoch 41, Train Loss: 0.1894\n",
      "Epoch 42, Train Loss: 0.1861\n",
      "Epoch 43, Train Loss: 0.1805\n",
      "Epoch 44, Train Loss: 0.1823\n",
      "Epoch 45, Train Loss: 0.1777\n",
      "Epoch 46, Train Loss: 0.1756\n",
      "Epoch 47, Train Loss: 0.1785\n",
      "Epoch 48, Train Loss: 0.1728\n",
      "Epoch 49, Train Loss: 0.1770\n",
      "Epoch 50, Train Loss: 0.1732\n",
      "Epoch 51, Train Loss: 0.1725\n",
      "Epoch 52, Train Loss: 0.1740\n",
      "Epoch 53, Train Loss: 0.1714\n",
      "Epoch 54, Train Loss: 0.1700\n",
      "Epoch 55, Train Loss: 0.1700\n",
      "Epoch 56, Train Loss: 0.1708\n",
      "Epoch 57, Train Loss: 0.1695\n",
      "Epoch 58, Train Loss: 0.1682\n",
      "Epoch 59, Train Loss: 0.1640\n",
      "Epoch 60, Train Loss: 0.1654\n",
      "Epoch 61, Train Loss: 0.1647\n",
      "Epoch 62, Train Loss: 0.1629\n",
      "Epoch 63, Train Loss: 0.1638\n",
      "Epoch 64, Train Loss: 0.1635\n",
      "Epoch 65, Train Loss: 0.1624\n",
      "Epoch 66, Train Loss: 0.1599\n",
      "Epoch 67, Train Loss: 0.1586\n",
      "Epoch 68, Train Loss: 0.1594\n",
      "Epoch 69, Train Loss: 0.1578\n",
      "Epoch 70, Train Loss: 0.1605\n",
      "Epoch 71, Train Loss: 0.1572\n",
      "Epoch 72, Train Loss: 0.1559\n",
      "Epoch 73, Train Loss: 0.1605\n",
      "Epoch 74, Train Loss: 0.1550\n",
      "Epoch 75, Train Loss: 0.1551\n",
      "Epoch 76, Train Loss: 0.1549\n",
      "Epoch 77, Train Loss: 0.1563\n",
      "Epoch 78, Train Loss: 0.1553\n",
      "Epoch 79, Train Loss: 0.1532\n",
      "Epoch 80, Train Loss: 0.1518\n",
      "Epoch 81, Train Loss: 0.1532\n",
      "Validation Accuracy for n=9: 0.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for n=9: 0.9524\n",
      "Accuracies across different n values: [(9, 0.9524074074074074)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run for each n value and collect accuracies\n",
    "results = []\n",
    "# learning_rate: 0.008705054471236994\n",
    "# batch_size: 17\n",
    "# layer1_units: 92\n",
    "# layer2_units: 52\n",
    "# prior_mu: 0.46796382181206203\n",
    "# prior_sigma: 0.4384207640007753\n",
    "# epochs: 100\n",
    "# Acc: 0.9348\n",
    "\n",
    "# learning_rate: 0.003992368422485689\n",
    "# batch_size: 121\n",
    "# layer1_units: 73\n",
    "# layer2_units: 54\n",
    "# prior_mu: 0.5103986684212475\n",
    "# prior_sigma: 0.29950393862614066\n",
    "# epochs: 81\n",
    "\n",
    "hyper_params9 = {\n",
    "    'prior_mu': 0.5103986684212475,\n",
    "    'prior_sigma': 0.29950393862614066,\n",
    "    'layer1_units': 73,\n",
    "    'layer2_units': 54,\n",
    "    'batch_size': 121,\n",
    "    'learning_rate': 0.003992368422485689,\n",
    "    'epochs': 81\n",
    "}\n",
    "possible_n_vals = [9]\n",
    "for n in tqdm(possible_n_vals):\n",
    "    accuracy = run_bayesian_nn(n, hyper_params9)\n",
    "    results.append((n, accuracy))\n",
    "\n",
    "print(\"Accuracies across different n values:\", results)\n",
    "\n",
    "# Threshold grid for each n value\n",
    "thresh_grid = {\n",
    "    '9': 0.95,  \n",
    "    '12': 0.925,\n",
    "    '15': 0.90,\n",
    "    '18': 0.875,\n",
    "    '24': 0.80,\n",
    "    '30': 0.75,\n",
    "    '45': 0.70\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
